# -*- coding: cp1251 -*-
"""gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iYs-ApTLM7RP_ZGbOfYt84zZ6w7tr0uZ

Ќу типа, у нас 4 сети: G, F, DG и DF. ѕервые 2 это пр€мой и
обратный генераторы, а последние 2 - соответствующие
дискриминаторы. ќпишем шаг обучени€: в сайкл ган подаетс€ 2
батча (x и y) из 2 соответствующих датасетов. ќни груз€тс€
в соответствующие генераторы, и выдачи записываютс€:
G: x -> y_fake, F: y -> x_fake. ‘ейки груз€тс€ в
комплементарные генераторы дл€ восстановлени€
(G: x_fake -> y_rec, F: y_fake -> x_rec). —читаетс€ лосс как
сумма cycle loss (видимо, это просто сумма матожиданий
x_rec-x и y_rec-y) и gan loss (он считаетс€ из выдачи
дискриминаторов DG(y_fake) и DF(x_fake)). ¬ коде авторов был
еще какой-то добавочный член и какие-то непон€тные
коэффициенты, но это потом. ѕосле подсчета лосса считаютс€
производные и пересчитываютс€ веса генераторов (не забыть
заморозить веса дискриминаторов). ƒалее считаютс€ лоссы дл€
дискриминаторов (как среднее от gan loss дл€ фейковых и
исходных батчей), и пересчитываютс€ уже их веса (почему-то в
коде авторов при этом забывают заморозить веса генераторов,
хот€ теоретически надо бы; насколько € понимаю, оптимизатору
там заранее подаютс€ на вход конкретные веса, и он работает
только с ними).
"""

import torch
import torch.nn as nn
from torch.nn import init

from torchvision import transforms
from torch.utils.data import Dataset, DataLoader, RandomSampler

from skimage.io import imread
import matplotlib.pyplot as plt
from IPython.display import clear_output

import itertools
import os
import math
import numpy as np
from time import time

import argparse
from networks import Generator, Discriminator
from data_loader import Monet2PhotoDataset


parser = argparse.ArgumentParser()
parser.add_argument('--trainA', type=str, help='path to first training dataset',
                    default='trainA')
parser.add_argument('--trainB', type=str, help='path to another training dataset',
                    default='trainB')
parser.add_argument('--epochs', type=int, help='number of train epochs',
                    default=1)
parser.add_argument('--weights', type=bool, help='pre-counted weights for the model',
                    default=False)

args = parser.parse_args()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Process is working on', device, flush=True)


A_files=[]
B_files=[]

for img in os.listdir(args.trainA):
    A_files.append(os.path.join(args.trainA, img))
for img in os.listdir(args.trainB):
    B_files.append(os.path.join(args.trainB, img))
    
print('Datasets lengths are %d and %d respectively' % (len(A_files),len(B_files)))
max_length=max(len(A_files), len(B_files))


A_data=Monet2PhotoDataset(A_files)
B_data=Monet2PhotoDataset(B_files)

g = Generator().to(device)
f = Generator().to(device)
dg = Discriminator().to(device)
df = Discriminator().to(device)


if args.weights:
    checkpoint = torch.load('model_weights.json')
    g.load_state_dict(checkpoint['g_state_dict'],map_location=torch.device(device))
    f.load_state_dict(checkpoint['f_state_dict'],map_location=torch.device(device))
    dg.load_state_dict(checkpoint['dg_state_dict'],map_location=torch.device(device))
    df.load_state_dict(checkpoint['df_state_dict'],map_location=torch.device(device))


cycle_opt=torch.optim.Adam(itertools.chain(g.parameters(), f.parameters()), lr=0.0002)
gan_opt=torch.optim.Adam(itertools.chain(dg.parameters(), df.parameters()), lr=0.0002)

gan_crit=nn.BCEWithLogitsLoss()
cycle_crit=nn.L1Loss()

# шаг обучени€ будет выгл€деть как-то так:
torch.autograd.set_detect_anomaly(True)
def train_step(x, y, batch_size=1):
    x=x.to(device)
    y=y.to(device)
    # сначала прогон€ем батчи через генераторы туда и обратно
    y_fake=g(x)
    x_fake=f(y)
    x_rec=f(y_fake)
    y_rec=g(x_fake)
    g_qual=dg(x_fake)
    f_qual=df(y_fake)
    
    # морозим дискриминаторы
    for par in itertools.chain(dg.parameters(), df.parameters()):
        par.requires_grad=False    

    # считаем лосс дл€ генераторов  
    cycle_loss=cycle_crit(x_rec, x)+cycle_crit(y_rec, y) \
    +gan_crit(g_qual, torch.ones(g_qual.shape).to(device)) \
    +gan_crit(f_qual, torch.ones(f_qual.shape).to(device))
    cycle_opt.zero_grad()
    # считаем производные
    cycle_loss.backward(retain_graph=True)
    # обновл€ем веса
    cycle_opt.step()
    # тут оптимизируем дискриминаторы
    for par in itertools.chain(dg.parameters(), df.parameters()):
        par.requires_grad=True    

    g_qual=dg(x_fake.detach())
    gan_opt.zero_grad()
    gan_loss_dg=0.5*(gan_crit(dg(y), torch.ones(g_qual.shape).to(device)) \
                     +gan_crit(g_qual, torch.zeros(g_qual.shape).to(device)))
    gan_loss_dg.backward()

    f_qual=df(y_fake.detach())
    gan_loss_df=0.5*(gan_crit(df(x), torch.ones(f_qual.shape).to(device)) \
                     +gan_crit(f_qual, torch.zeros(f_qual.shape).to(device)))
    gan_loss_df.backward()
    gan_opt.step()

    return float(cycle_loss), 0.5*(float(gan_loss_dg)+float(gan_loss_df))

f.train()
g.train()

for epoch in range(args.epochs):
    t0=time()
    A_sampler=RandomSampler(A_data, replacement = True,
                            num_samples = max_length)
    A=DataLoader(A_data, batch_size=1, sampler=A_sampler)
    B=DataLoader(B_data, batch_size=1, shuffle=True)
    cl=0
    gl=0
    for a_pic, b_pic in zip(A, B):
        loss1, loss2=train_step(a_pic, b_pic)
        cl += loss1/max_length
        gl += loss2/max_length
    t1=time()
    print('Epoch %d' % epoch)
    print('Cycle loss: %f' % cl)
    print('GAN loss: %f' % gl)
    print('Time: %f seconds' % t1-t0, flush=True)
    torch.save({
                'g_state_dict': g.state_dict(),
                'f_state_dict': f.state_dict(),
                'dg_state_dict': dg.state_dict(),
                'df_state_dict': df.state_dict()
                }, 'model_weights.json')
    


